---
title: "Visualization"
author: "Enrique Nusi"
date: "8/3/2020"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


##STEP 1: Load libraries and choose data set to import; build function to read in glossary

``` {r import data, echo=FALSE}

library(tidyverse) 
library(tidytext) 
library(textstem)
library(ggraph)
library(ggforce)
library(igraph)
library(highcharter)
library(lubridate)

imported_data <- read_csv("dataset_FILTERED.csv") #Use data filtered through a custom word list

library(googlesheets4)
library(data.table)

glossProc <- function(URL){ #Glossary reading function
  glossaryWords <- read_sheet(URL, col_types = "c") %>% 
    mutate(word = tolower(Concept)) %>%
    mutate(others = tolower(`Associated Terms`)) %>% 
    select(word, others) %>% 
    mutate(word = str_replace_all(word, "\\(", "\\\\(")) %>% 
    mutate(word = str_replace_all(word, "\\)", "\\\\)")) %>% 
    #mutate(word = paste("\\b", word, "\\b", sep = "")) %>%
    mutate(others = str_replace_all(others, "\\(", "\\\\(")) %>% 
    mutate(others = str_replace_all(others, "\\)", "\\\\)")) %>% 
    filter(!word %in% c("terms", "from", "custom list", "to", "exclude"))
  
  filter_words <- c(glossaryWords$word, glossaryWords$others)
  filter_words <- filter_words[!is.na(filter_words)]
  
  filter_list <- c()
  for(i in filter_words){
    i <- str_replace_all(i, ";", ",")
    i <- str_split(i, ", ")
    filter_list <- c(filter_list, unlist(i))
  }
  glossaryWords <- paste("\\b", unlist(filter_list), "\\b", sep = "")
  glossaryWords <- glossaryWords[!is.na(glossaryWords)]
  return(tolower(paste(glossaryWords, collapse="|")))
}

glossWords <- glossProc("URL_TO_CUSTOM_WORDLIST(OR_ADD_A_LIST_DIRECTLY")
gargle::gargle_oauth_cache()

```


##STEP 2: Tidy data and glossary words and generate term frequency chart (save as termfreq_dataset.png, at least 1200 for width)

```{r term freq, echo=FALSE}

stage1_text <- imported_data %>% #Puts data into a tidy format, removes extra spacing characters
  mutate(match_term = trimws(match_term)) %>% 
  select(UserName, PublishDate, match_term) %>% 
  mutate(match_term = str_replace_all(match_term, "c\\(", "")) %>% 
  mutate(match_term = str_replace_all(match_term, "\\)", "")) %>% 
  mutate(match_term = str_replace_all(match_term, "\\\\", "")) %>% 
  mutate(match_term = str_replace_all(match_term, "\"", "")) %>% 
  mutate(match_term = str_split(match_term, ",")) %>%
  unnest(match_term) %>% 
  mutate(match_term = case_when(match_term == "character(0)" ~ "",
                                match_term != "character(0)" ~ match_term)) %>%
  filter(!is.na(match_term))

stage1_time <- stage1_text %>% #Counts match term occurrences 
  mutate(match_term = trimws(match_term)) %>%
  group_by(match_term) %>% 
  summarize(N = n()) %>% 
  mutate(freq = N) %>%
  ungroup() %>% 
  arrange(desc(freq)) %>% 
  filter(match_term != "character(0")

stage1_time %>% #Generates term freq chart
  filter(!is.na(match_term)) %>% 
  filter(!match_term %in% c("list", "of", "words from custom glossary", "to", "exclude")) %>%
  mutate(match_word = factor(match_term, match_term)) %>%
  arrange(desc(freq)) %>% 
  head(20) %>%
  hchart("column", hcaes(x = reorder(match_term, freq), y = freq)) %>% 
  hc_title(text = paste("Frequency of Custom Terms Used")) %>% 
  hc_yAxis(title =list(text="Number of Occurrences of Custom Terms")) %>% 
  hc_xAxis(title = list(text="Custom Term")) %>% 
  hc_add_theme(hc_theme_flat(colors = c("red", "blue", "green")))

```


##STEP 3: Generate word clouds for match_term and textWords variables (must be run separately, save as wc_match_term.png and wc_textWords.png no need to resize these)

```{r wordcloud, echo=FALSE}

library(wordcloud)
library(RColorBrewer)
library(dplyr)

plt <- brewer.pal(8, "Set2") #settings for color palette


imported_data <- imported_data %>%  transform(match_term = strsplit(match_term, ",")) %>% #If a row has more than one term, splits concatenated terms into their own rows
  unnest(cols=c(match_term)) %>% 
  filter(match_term != "character(0)") %>% 
  mutate(match_term = str_replace_all(match_term, "\"", "")) %>% 
  mutate(match_term = str_replace_all(match_term, "\\)", "")) %>% 
  mutate(match_term = str_replace_all(match_term, "c\\(", "")) %>% 
  mutate(match_term = str_replace_all(match_term, " (?=.*)", "")) %>%
  filter(!match_term %in% c("list", "of", "words from custom glossary", "to", "exclude"))
imported_data1 <- count(imported_data, match_term)

set.seed(100)
wordcloud(words=imported_data1$match_term, #Generates word cloud for match_terms
          freq=imported_data1$n,
          scale=c(3,0.5), #Largest font size to smallest
          min.freq = 5, #Only displays words that appear X number of times
          random.order = FALSE, #Highest occurrences are larger font and at the center
          color=plt)

imported_data2 <- imported_data %>% 
  unnest_tokens(word, textWords) %>% 
  anti_join(stop_words) %>%
  count(word) %>% 
  arrange(desc(n)) %>%
  top_n(n = 100)

wordcloud(words=imported_data2$word, #Generates word cloud for textWords
          freq=imported_data2$n,
          scale=c(3,0.5), #Largest font size to smallest
          min.freq = 5, #Only displays words that appear X number of times
          random.order = FALSE, #Highest occurrences are larger font and at the center
          color=plt)

```


##STEP 4: Generate simple time-series charts for each word on the term frequency chart (save as ts_TERM.png, at least 1200 for width)

``` {r simple time series, echo=FALSE, self_contained=FALSE}

library(scales)

TERM = "glossword"   #Put word from term freq chart here, no spaces

chart <- imported_data %>% 
  filter(match_term == TERM) %>% 
  mutate(day = lubridate::floor_date(PublishDate, unit = "day")) %>% #Can set floor date to "week", "month", "hour", "year" etc
  count(day) 

chart$day <- as.POSIXct(chart$day)
chart_sd <- sd(chart$n)
chart_avg <- mean(chart$n)
display_sd <- paste("Standard Deviation (red line is x2) =", as.character(round(chart_sd, digits=3)))
display_avg <- paste("Average (black line) =", as.character(round(chart_avg, digits=3)))
display_title <- paste("Term Usage Tracker:", TERM)

chart$test <- sd(chart$n)

chart %>%
  ggplot(aes(x = day, y = n)) +
  ggtitle(display_title) +
  geom_smooth(aes(x=day, y=test), colour="black") +
  geom_smooth(aes(x=day, y=(test+(chart_sd)*2)), colour="red") +
  geom_col(fill = "steelblue") +
    labs(caption = c(display_sd, display_avg)) + 
    theme(plot.caption = element_text(hjust=c(1, 0), size=11)) +
  scale_x_datetime(date_breaks="1 day") + #If you change the floor date settings, remember to change it here too
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +
  xlab("Date") +
  ylab("Frequency of Term Usage")

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
